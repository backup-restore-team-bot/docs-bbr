---
title: Experimental Features
owner: BBR
---

This topic highlights features that are only recommended for advanced users of BBR.

## <a id="ulf-flag"></a> The --unsafe-lock-free Flag

As of v1.9.0, the BBR CLI has an `--unsafe-lock-free` flag.
This flag should only be used by expert users of BBR, for reasons that this page highlights.
If you use this flag during a backup operation, BBR will skip running the lock and unlock scripts in
your deployment.
In the case of backing up a Cloud Foundry deployment, you would prevent Cloud Foundry API downtime
but could cause an inconsistent backup.

This topic covers covers:

* Why your backup might be inconsistent
* Inconsistencies we have observed in testing and their consequences
* Potential inconsistencies that we have not observed and their potential mitigations

This topic does not speculate about the consequences of using the `--unsafe-lock-free` flag for
backing up any deployment other than Cloud Foundry.

## <a id="tshoot"></a> Troubleshooting the --unsafe-lock-free Flag

Cloud Foundry is a distributed system, which relies on distributed state.
For example, consider a running app:

* The Cloud Controller keeps the name of the app, the route it has claimed, and other similar data,
in the Cloud Controller Database (CCDB)
* The actual binary bits that form the running app, known as the droplet, are stored in the blobstore

If you back up Cloud Foundry while an app is being pushed, your backup of the CCDB might contain a
reference to this app, while your backup of the blobstore does not contain the app's droplet.
If you attempt to restore this backup, this app fails to start.

To avoid this sort of problem, BBR locks Cloud Foundry before taking a backup.
As a side-effect, the Cloud Foundry API goes down during the critical phase of the backup.
The `--unsafe-lock-free` flag disables this safety feature.
If you use it you will prevent Cloud Foundry API downtime, but you will not be protected from
backup inconsistencies such as the one described here.

### <a id="missing-blob"> Missing Blob

#### Symptom
After restoring this inconsistent backup, some apps failed to start.
Running `cf events APP-NAME` yields something like the following:

```bigquery
time                          event                       actor          description
2020-10-28T11:10:21.00+0000   app.crash                   APP-NAME       index: 0, reason: CRASHED, cell_id: 03fdc92e-8d5e-447c-a894-52f62b5f9c8e, instance: 2e2ae69a-c750-4da6-7339-5240, exit_description: Downloading droplet failed
```
This is a sign that the app's droplet is missing from the blobstore.

#### Explanation

In testing, we caused this issue by artificially delaying the blobstore backup part of the BBR backup process, while concurrently deleting an app.

We therefore expect the following:

* It seems likely that this issue could occur if a user deletes an app at a critical point during a backup process.
* This issue might also occur if a user creates an app at a critical point during a backup process.

In both cases, we expect only the newly deleted or created app to be affected.

**Possible mitigations**

*Reactive fix*

If the app's package is present in the blobstore, we can fix the issue by running
`cf restage APP-NAME`.

However, if the droplet is missing due to an inconsistent backup, there is a good chance that the
corresponding package is also missing. In this case, the only way to recover is to re-push the app.

*Prevention*

You can prevent this issue altogether by:

* Using an external blobstore, such as Minio
* Using the native replication features of your external blobstore to keep your own backups separately from BBR
* Setting a retention policy on your replica blobstore, so that no files are truly deleted until they
are marked as deleted for a certain number of days

Before you perform a `bbr restore`, first restore your blobstore from your replica or swap out the
live store for the replica.

This gives you a certain period of time in which all your backups are valid.
If you restore a backup older than that period, you will still be susceptible to this issue.

### Unstarted App

After restoring, some apps did not even attempt to start.

**When might this happen?**

If an app is pushed at a critical point during the backup process, the app can get created before the
Cloud Controller database (CCDB) is backed up, but started after the CCDB is backed up.
The result is an app which is backed up in a stopped state.

**Possible Mitigations**

Run `cf start APP-NAME`.
If this fails, check that you are not missing blobs as described above.

### An Incomplete User

After restoring these inconsistent backups, we observed that:

* A Cloud Foundry user existed who had no name and no credentials
* A set of Cloud Foundry user credentials existed with no corresponding user

**When might this happen?**

In testing, we caused variants of this issue by creating or deleting a Cloud Foundry user at a
critical point during the backup process.

In one case, the backup took a snapshot of the Cloud Controller database (CCDB) in a state in which
the user structure was created, but no name was assigned.
Furthermore, no credentials were created for the user in the UAA Database (UAADB), so the user was
not usable.

In another case, the backup took a snapshot of the CCDB after a user was deleted, and the UAADB
before the user was deleted. This left a set of garbage credentials in the UAADB which were connected
to no users, and consequently had no access to anything in the system.

**Possible Mitigations**

Delete the half-created user if possible.

You can avoid this issue entirely by not creating or deleting users during the backup process.

You can also avoid this issue by using LDAP or similar, rather than managing users directly in Cloud Foundry.

### What additional possible inconsistencies could we imagine occurring?

Above we listed the issues we observed during testing.
In addition, we could imagine the following possible scenarios.
For each of the following, we either chose not to investigate or were unable to create the issue in
our lab.
However, the lab is not the field, so it is worth considering these possibilities before relying on
`--unsafe-lock-free` in production.

**An app exists in CCDB, but not in either the networkingDB or the routingDB.**

We could imagine an app appearing to start successfully, but not being reachable from the outside
world.
Or similarly, for container-to-container networking routes to be unavailable, so your microservices
cannot talk to each other as expected.

We tried quite hard to force this error case in the lab, but were unable to.
Apps in Cloud Foundry have the power to register their own routes, so it is possible that the error
did briefly occur but self-corrected before we were able to observe it.

**A Route Exists with No App**

If this happened, we would expect a route to be restored, pointing to an app that no-longer exists.
This could conceivably be a security risk if the route just so happened to accidentally point at a
container which was not intended to be exposed to the public internet.

However, routes in Cloud Foundry are intentionally short-lived, and must be constantly renewed by the
app that claims them, so even in the worst case we expect this problem would self-correct shortly
after the restore.

**An App has CredHub Bindings <%# to data services? %> Which Are Not in CredHub DB**

If this happened, we would expect an app to believe it has access to some data service, when in fact
those credentials no longer exist.
This would result in the app failing to access the data service at runtime, and possibly crashing or
behaving in unexpected ways as a result.

**An App is Missing an Autoscaler Entry**

If this happened, an app which we expected to autoscale would fail to autoscale.

We did not investigate this issue because it likely to be caused by a locking-backup occurring
slightly earlier than expected, not the `--unsafe-lock-free` flag.

**An Autoscaler Entry is Missing an App**

If this happened, the autoscaler might attempt to scale an app that does not exist and fail.

We did not investigate this issue, because we expect it would be very low severity, and we do not
expect our users of `--unsafe-lock-free` use autoscaler.

**A space could be in CCDB owned by a user who does not exist in UAADB**

If this happened, we worried that a Cloud Foundry Space might be effectively inaccessible, with its
users missing.

We failed to force this error in the lab.
This is unsurprising because the Cloud Controller seems to manage user and space creation and
deletion in a sensible order.

**Usage Events might be missing for apps, spaces, or service instances that exist, or might exist for
apps, spaces, or service instances that did not make it into the backup.**

Usage Events is a messaging system, and this is the usual problem with snapshotting messaging
systems. With or without locks, it is possible to lose messages during a backup.
For more information, see the
[Cloud Foundry documentation](https://docs.cloudfoundry.org/running/managing-cf/usage-events.html).

A message might be fired just before the backup was taken, but not safely persist until after the
backup was taken.
If this happens, the observed behavior of the system is exactly as if the message were fired just
after the backup was taken.

This is both low-severity, and also could happen regardless of whether we are using locks.
For this reason, we did not investigate it.
